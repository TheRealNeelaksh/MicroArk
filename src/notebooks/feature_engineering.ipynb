{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Preparation and Feature Engineering\n",
                "\n",
                "This notebook documents the process of cleaning the raw metadata and generating species-level features for the MicroArk project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Define paths relative to the project root\n",
                "# Assuming this notebook is in src/notebooks/\n",
                "project_root = Path(\"../../\").resolve()\n",
                "input_file = project_root / \"data\" / \"metalog_raw.csv\"\n",
                "output_file = project_root / \"data\" / \"species_features.csv\"\n",
                "\n",
                "print(f\"Project Root: {project_root}\")\n",
                "print(f\"Input File: {input_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "Load the raw metadata CSV downloaded from Metalog."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not input_file.exists():\n",
                "    print(f\"Error: {input_file} not found.\")\n",
                "else:\n",
                "    df = pd.read_csv(input_file, low_memory=False)\n",
                "    print(f\"Loaded DataFrame with shape: {df.shape}\")\n",
                "    display(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing & Column Mapping\n",
                "\n",
                "We need to map specific columns to our target features:\n",
                "- `host_species` <--- `host_tax_id` (Taxonomic ID is more reliable)\n",
                "- `country` <--- `location` (Extracted from string)\n",
                "- `collection_year` <--- `collection_date` (Extracted year)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Map host_species\n",
                "if 'host_tax_id' in df.columns:\n",
                "    df['host_species'] = df['host_tax_id']\n",
                "else:\n",
                "    print(\"Error: 'host_tax_id' column missing.\")\n",
                "\n",
                "# Map country\n",
                "if 'location' in df.columns:\n",
                "    df['country'] = df['location'].astype(str).apply(lambda x: x.split(':')[0].strip() if pd.notnull(x) else \"Unknown\")\n",
                "else:\n",
                "    df['country'] = \"Unknown\"\n",
                "\n",
                "# Map collection_year\n",
                "if 'collection_date' in df.columns:\n",
                "    df['collection_year'] = pd.to_datetime(df['collection_date'], errors='coerce').dt.year\n",
                "else:\n",
                "    df['collection_year'] = 0\n",
                "\n",
                "# Ensure coordinates\n",
                "for col in ['latitude', 'longitude']:\n",
                "    if col not in df.columns:\n",
                "        df[col] = 0\n",
                "\n",
                "print(\"Columns mapped.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning\n",
                "\n",
                "1. Drop rows where `host_species` is NaN.\n",
                "2. Filter out species that have fewer than 5 samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "before_count = len(df)\n",
                "df = df.dropna(subset=[\"host_species\"])\n",
                "print(f\"Dropped {before_count - len(df)} rows with missing species info.\")\n",
                "\n",
                "# Filter < 5 samples\n",
                "species_counts = df[\"host_species\"].value_counts()\n",
                "valid_species = species_counts[species_counts >= 5].index\n",
                "df_filtered = df[df[\"host_species\"].isin(valid_species)].copy()\n",
                "\n",
                "print(f\"Retained {len(valid_species)} species with >= 5 samples.\")\n",
                "print(f\"Final sample count: {len(df_filtered)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Creation\n",
                "\n",
                "Group by `host_species` and calculate:\n",
                "- `num_samples`: Total count\n",
                "- `num_countries`: Unique countries\n",
                "- `year_span`: Max year - Min year\n",
                "- `lat_variance`: Variance of latitude\n",
                "- `long_variance`: Variance of longitude"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "grouped = df_filtered.groupby(\"host_species\")\n",
                "\n",
                "features = pd.DataFrame({\n",
                "    \"num_samples\": grouped.size(),\n",
                "    \"num_countries\": grouped[\"country\"].nunique(),\n",
                "    \"year_span\": grouped[\"collection_year\"].max() - grouped[\"collection_year\"].min(),\n",
                "    \"lat_variance\": grouped[\"latitude\"].var(),\n",
                "    \"long_variance\": grouped[\"longitude\"].var()\n",
                "})\n",
                "\n",
                "features = features.fillna(0)\n",
                "features.reset_index(inplace=True)\n",
                "\n",
                "display(features.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Save Results\n",
                "Save the generated features to a CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features.to_csv(output_file, index=False)\n",
                "print(f\"Saved features to {output_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}